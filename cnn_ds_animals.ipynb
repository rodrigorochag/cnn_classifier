{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOe+g4t/SPU7ZzfI3DldoBg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodrigorochag/cnn_classifier/blob/main/cnn_ds_animals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y_YcYzr72WMT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from plotly.subplots import make_subplots\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from PIL import Image\n",
        "import plotly.offline as pyo\n",
        "from IPython.display import display\n",
        "# import torch\n",
        "# import torchvision\n",
        "# import torchvision.transforms as transforms\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_info = {\n",
        "    \"username\": \"user_kaggle\",\n",
        "    \"key\": \"api_key\"\n",
        "}"
      ],
      "metadata": {
        "id": "MmKgT_PM6Bsw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Kaggle library\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Set Kaggle credentials\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Replace the following with your Kaggle username and API key\n",
        "\n",
        "\n",
        "# Save Kaggle credentials to a JSON file\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as file:\n",
        "    json.dump(kaggle_info, file)\n",
        "\n",
        "# Change the permissions of the file\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d likhon148/animal-data\n",
        "# Unzip the dataset\n",
        "#!mkdir /content/gpiosenka/sports-classification\n",
        "!unzip -q animal-data.zip -d animal-data\n",
        "\n",
        "# List the contents of the directory\n",
        "!ls /content/animal-data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWqRqnsT2YFI",
        "outputId": "d0ea5497-0140-4561-9c62-fbafe2e1d78b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading animal-data.zip to /content\n",
            " 94% 34.0M/36.3M [00:00<00:00, 150MB/s] \n",
            "100% 36.3M/36.3M [00:00<00:00, 137MB/s]\n",
            "animal_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#numpydata = np.array(img)\n",
        "\n",
        "# Dictionary to store files with labels\n",
        "train_images = {}\n",
        "path = \"/content/animal-data/animal_data/Bear\"\n",
        "\n",
        "# Iterate over files in the directory\n",
        "for file_name in os.listdir(path):\n",
        "    # Check if current item is a file\n",
        "    if os.path.isfile(os.path.join(path, file_name)):\n",
        "        # Add filename and label to the dictionary\n",
        "        train_images[file_name] = '0'\n",
        "\n",
        "print(train_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSXTaROM3Ovq",
        "outputId": "d025ef29-6332-4e15-bf5d-d13f661c9b1c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Bear_28.jpg': '0', 'bear_1_3.jpg': '0', 'Bear_30_3.jpg': '0', 'Bear_16.jpeg': '0', 'Bear_24_2.jpg': '0', 'Bear_2_1.jpg': '0', 'Bear_13_4.jpg': '0', 'Bear_20_3.jpg': '0', 'bear_4_3.jpg': '0', 'Bear_17_1.jpg': '0', 'Bear_3.jpg': '0', 'Bear_28_1.jpg': '0', 'Bear_5.jpeg': '0', 'Bear_26_3.jpg': '0', 'Bear_25_1.jpg': '0', 'Bear_6_1.jpg': '0', 'Bear_7_3.jpg': '0', 'Bear_10_1.jpg': '0', 'bear_8_2.jpg': '0', 'Bear_9_1.jpg': '0', 'Bear_12.jpeg': '0', 'Bear_27_1.jpg': '0', 'Bear_10_3.jpg': '0', 'Bear_17_3.jpg': '0', 'bear_8_3.jpg': '0', 'Bear_3_1.jpg': '0', 'Bear_7.jpeg': '0', 'Bear_18.jpeg': '0', 'Bear_9_4.jpg': '0', 'Bear_20_4.jpg': '0', 'Bear_16_1.jpg': '0', 'Bear_24_3.jpg': '0', 'Bear_9_2.jpg': '0', 'Bear_22_2.jpg': '0', 'Bear_6_2.jpg': '0', 'Bear_16_2.jpg': '0', 'Bear_2.jpeg': '0', 'Bear_23_2.jpg': '0', 'Bear_29_1.jpg': '0', 'Bear_14_1.jpg': '0', 'Bear_27_2.jpg': '0', 'Bear_24_1.jpg': '0', 'Bear_11.jpeg': '0', 'Bear_15_3.jpg': '0', 'Bear_12_1.jpg': '0', 'bear_4_4.jpg': '0', 'Bear_5_1.jpg': '0', 'Bear_30_1.jpg': '0', 'Bear_19_3.jpg': '0', 'Bear_10_2.jpg': '0', 'Bear_11_3.jpg': '0', 'Bear_21_1.jpg': '0', 'Bear_26.jpeg': '0', 'Bear_9_3.jpg': '0', 'bear_4_1.jpg': '0', 'Bear_2_3.jpg': '0', 'Bear_30.jpeg': '0', 'Bear_16_3.jpg': '0', 'Bear_30_2.jpg': '0', 'bear_1_4.jpg': '0', 'Bear_23.jpeg': '0', 'Bear_14_2.jpg': '0', 'Bear_13_2.jpg': '0', 'Bear_28_3.jpg': '0', 'Bear_13.jpeg': '0', 'Bear_18_3.jpg': '0', 'Bear_5_3.jpg': '0', 'Bear_29.jpeg': '0', 'Bear_29_3.jpg': '0', 'Bear_26_2.jpg': '0', 'Bear_25_2.jpg': '0', 'Bear_9.jpeg': '0', 'Bear_29_2.jpg': '0', 'bear_1_1.jpg': '0', 'Bear_7_1.jpg': '0', 'Bear_20_1.jpg': '0', 'Bear_22_3.jpg': '0', 'Bear_15_2.jpg': '0', 'Bear_13_3.jpg': '0', 'Bear_2_2.jpg': '0', 'Bear_27_3.jpg': '0', 'Bear_18_1.jpg': '0', 'Bear_14_3.jpg': '0', 'Bear_18_4.jpg': '0', 'Bear_20.jpeg': '0', 'Bear_21_3.jpg': '0', 'Bear_3_3.jpg': '0', 'Bear_6.jpg': '0', 'Bear_27.jpeg': '0', 'bear_8.jpg': '0', 'Bear_7_2.jpg': '0', 'Bear_11_2.jpg': '0', 'Bear_21.jpeg': '0', 'bear_8_1.jpg': '0', 'Bear_19.jpeg': '0', 'bear_4_2.jpg': '0', 'Bear_23_1.jpg': '0', 'Bear_28_2.jpg': '0', 'Bear_5_2.jpg': '0', 'Bear_14.jpeg': '0', 'Bear_13_1.jpg': '0', 'Bear_24.jpeg': '0', 'Bear_10.jpg': '0', 'Bear_17_2.jpg': '0', 'Bear_22.jpeg': '0', 'Bear_11_1.jpg': '0', 'Bear_26_1.jpg': '0', 'Bear_23_3.jpg': '0', 'Bear_12_2.jpg': '0', 'Bear_3_2.jpg': '0', 'bear_1_2.jpg': '0', 'bear_8_4.jpg': '0', 'bear_1.jpg': '0', 'bear_4.jpg': '0', 'Bear_25.jpeg': '0', 'Bear_17.jpeg': '0', 'Bear_15_1.jpg': '0', 'Bear_20_2.jpg': '0', 'Bear_12_3.jpg': '0', 'Bear_21_2.jpg': '0', 'Bear_19_2.jpg': '0', 'Bear_15.jpeg': '0', 'Bear_22_1.jpg': '0', 'Bear_18_2.jpg': '0', 'Bear_19_1.jpg': '0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#numpydata = np.array(img)\n",
        "\n",
        "# Dictionary to store files with labels\n",
        "train_images = []\n",
        "path = \"/content/animal-data/animal_data/Bear\"\n",
        "\n",
        "# Iterate over files in the directory\n",
        "for file_name in os.listdir(path):\n",
        "    # Check if current item is a file\n",
        "    if os.path.isfile(os.path.join(path, file_name)):\n",
        "        # Add filename and label to the dictionary\n",
        "        #train_images[file_name] = '0'\n",
        "        train_images = np.array(file_name)\n",
        "\n",
        "\n",
        "print(train_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiNlNYx1BMIv",
        "outputId": "f6605f4b-74bf-4c1f-c192-4eaef292af39"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bear_19_1.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOq71KM6DS-a",
        "outputId": "907347ec-8fd7-436c-b7c6-9970700cf4a7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array('Bear_19_1.jpg', dtype='<U13')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "train_images = []\n",
        "path = \"/content/animal-data/animal_data/Bear\"\n",
        "\n",
        "# Iterate over files in the directory\n",
        "for file_name in os.listdir(path):\n",
        "    # Check if current item is a file\n",
        "    if os.path.isfile(os.path.join(path, file_name)):\n",
        "        # Read the image\n",
        "        image = cv2.imread(os.path.join(path, file_name))\n",
        "        # Convert the image to a numpy array\n",
        "        if image is not None:\n",
        "            train_images.append(np.array(image))\n",
        "        else:\n",
        "            print(f\"Unable to read image: {file_name}\")\n",
        "\n",
        "# Convert the list of images to a numpy array\n",
        "train_images_array = np.array(train_images)\n",
        "\n",
        "print(train_images_array)\n"
      ],
      "metadata": {
        "id": "Ll3DNDtkDEBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_images_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVd1C8TnD6dR",
        "outputId": "775cdc9e-9d94-48c1-b923-e1b472d97fee"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_images_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFl1_UuYDlZL",
        "outputId": "db8f5779-97f4-4730-893e-2d1cca97cbc4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}